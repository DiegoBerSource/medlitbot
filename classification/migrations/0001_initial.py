# Generated by Django 5.2.5 on 2025-08-22 21:55

import classification.models
import django.core.validators
import django.db.models.deletion
from django.conf import settings
from django.db import migrations, models


class Migration(migrations.Migration):

    initial = True

    dependencies = [
        ('dataset_management', '0001_initial'),
        migrations.swappable_dependency(settings.AUTH_USER_MODEL),
    ]

    operations = [
        migrations.CreateModel(
            name='MLModel',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', models.CharField(help_text='Name of the model', max_length=200)),
                ('description', models.TextField(blank=True, help_text='Description of the model and its purpose')),
                ('model_type', models.CharField(choices=[('bert', 'BERT-based (BioBERT/ClinicalBERT)'), ('traditional', 'Traditional ML (SVM/Random Forest)'), ('hybrid', 'Hybrid Ensemble'), ('custom', 'Custom Architecture')], help_text='Type of ML model architecture', max_length=50)),
                ('parameters', models.JSONField(default=dict, help_text='Model hyperparameters and configuration')),
                ('model_path', models.FileField(blank=True, help_text='Path to the trained model file', null=True, upload_to=classification.models.model_upload_path, validators=[django.core.validators.FileExtensionValidator(allowed_extensions=['pkl', 'pth', 'safetensors', 'joblib'])])),
                ('status', models.CharField(choices=[('created', 'Created'), ('training', 'Training'), ('trained', 'Trained'), ('failed', 'Training Failed'), ('evaluating', 'Evaluating'), ('deployed', 'Deployed'), ('archived', 'Archived')], default='created', max_length=20)),
                ('is_trained', models.BooleanField(default=False, help_text='Whether the model has been successfully trained')),
                ('training_metrics', models.JSONField(default=dict, help_text='Training metrics (loss, accuracy, etc.)')),
                ('validation_metrics', models.JSONField(default=dict, help_text='Validation metrics during training')),
                ('test_metrics', models.JSONField(default=dict, help_text='Final test set evaluation metrics')),
                ('training_time_minutes', models.FloatField(blank=True, help_text='Total training time in minutes', null=True)),
                ('num_epochs', models.IntegerField(blank=True, help_text='Number of training epochs completed', null=True)),
                ('best_epoch', models.IntegerField(blank=True, help_text='Epoch with best validation performance', null=True)),
                ('accuracy', models.FloatField(blank=True, help_text='Overall accuracy on test set', null=True)),
                ('f1_score', models.FloatField(blank=True, help_text='Macro F1 score on test set', null=True)),
                ('precision', models.FloatField(blank=True, help_text='Macro precision on test set', null=True)),
                ('recall', models.FloatField(blank=True, help_text='Macro recall on test set', null=True)),
                ('domain_performance', models.JSONField(default=dict, help_text='Performance metrics per medical domain')),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('updated_at', models.DateTimeField(auto_now=True)),
                ('training_started_at', models.DateTimeField(blank=True, help_text='When training started', null=True)),
                ('training_completed_at', models.DateTimeField(blank=True, help_text='When training completed', null=True)),
                ('is_deployed', models.BooleanField(default=False, help_text='Whether this model is currently deployed for inference')),
                ('deployment_url', models.URLField(blank=True, help_text='URL for deployed model API endpoint')),
                ('created_by', models.ForeignKey(blank=True, help_text='User who created this model', null=True, on_delete=django.db.models.deletion.SET_NULL, to=settings.AUTH_USER_MODEL)),
                ('dataset', models.ForeignKey(help_text='Dataset used for training', on_delete=django.db.models.deletion.CASCADE, related_name='models', to='dataset_management.Dataset')),
            ],
            options={
                'verbose_name': 'ML Model',
                'verbose_name_plural': 'ML Models',
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='ModelComparison',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('name', models.CharField(help_text='Name of the comparison experiment', max_length=200)),
                ('description', models.TextField(blank=True, help_text='Description of the comparison')),
                ('comparison_results', models.JSONField(default=dict, help_text='Detailed comparison results and metrics')),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('ml_models', models.ManyToManyField(help_text='Models being compared', to='classification.mlmodel')),
                ('test_dataset', models.ForeignKey(blank=True, help_text='Dataset used for model comparison', null=True, on_delete=django.db.models.deletion.SET_NULL, to='dataset_management.Dataset')),
            ],
            options={
                'verbose_name': 'Model Comparison',
                'verbose_name_plural': 'Model Comparisons',
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='TrainingJob',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('celery_task_id', models.CharField(help_text='Celery task ID for tracking', max_length=255, unique=True)),
                ('status', models.CharField(choices=[('pending', 'Pending'), ('running', 'Running'), ('completed', 'Completed'), ('failed', 'Failed'), ('cancelled', 'Cancelled')], default='pending', max_length=20)),
                ('progress_percentage', models.FloatField(default=0.0, help_text='Training progress (0-100%)')),
                ('current_epoch', models.IntegerField(default=0, help_text='Current training epoch')),
                ('total_epochs', models.IntegerField(help_text='Total planned epochs')),
                ('current_loss', models.FloatField(blank=True, help_text='Current training loss', null=True)),
                ('current_accuracy', models.FloatField(blank=True, help_text='Current training accuracy', null=True)),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('started_at', models.DateTimeField(blank=True, null=True)),
                ('completed_at', models.DateTimeField(blank=True, null=True)),
                ('error_message', models.TextField(blank=True, help_text='Error message if training failed')),
                ('traceback', models.TextField(blank=True, help_text='Full error traceback')),
                ('model', models.OneToOneField(on_delete=django.db.models.deletion.CASCADE, related_name='training_job', to='classification.mlmodel')),
            ],
            options={
                'verbose_name': 'Training Job',
                'verbose_name_plural': 'Training Jobs',
                'ordering': ['-created_at'],
            },
        ),
        migrations.CreateModel(
            name='ClassificationResult',
            fields=[
                ('id', models.BigAutoField(auto_created=True, primary_key=True, serialize=False, verbose_name='ID')),
                ('title', models.CharField(help_text='Article title used for classification', max_length=500)),
                ('abstract', models.TextField(help_text='Article abstract used for classification')),
                ('predicted_domains', models.JSONField(default=list, help_text='List of predicted medical domains')),
                ('confidence_scores', models.JSONField(default=dict, help_text='Confidence scores for each predicted domain')),
                ('all_domain_scores', models.JSONField(default=dict, help_text='Scores for all possible domains (for analysis)')),
                ('prediction_threshold', models.FloatField(default=0.5, help_text='Threshold used for binary classification decisions')),
                ('inference_time_ms', models.FloatField(blank=True, help_text='Time taken for inference in milliseconds', null=True)),
                ('true_domains', models.JSONField(blank=True, default=list, help_text='True medical domains (for evaluation purposes)')),
                ('created_at', models.DateTimeField(auto_now_add=True)),
                ('user_agent', models.CharField(blank=True, help_text='User agent of the request', max_length=500)),
                ('ip_address', models.GenericIPAddressField(blank=True, help_text='IP address of the request', null=True)),
                ('model', models.ForeignKey(on_delete=django.db.models.deletion.CASCADE, related_name='classification_results', to='classification.mlmodel')),
            ],
            options={
                'verbose_name': 'Classification Result',
                'verbose_name_plural': 'Classification Results',
                'ordering': ['-created_at'],
                'indexes': [models.Index(fields=['model', '-created_at'], name='classificat_model_i_732a8a_idx'), models.Index(fields=['created_at'], name='classificat_created_253d97_idx')],
            },
        ),
    ]
